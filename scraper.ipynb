{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22346da-458f-48c3-9c85-705191158133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6bf7d8-7460-41c8-8b40-03f2cffe7d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check and return if a particular text exists on the website\n",
    "\n",
    "def get_text(source, class_name, attr):\n",
    "    \n",
    "    try:\n",
    "        if source.find(class_=class_name) is None:\n",
    "            return np.NaN\n",
    "        elif source.find(class_=class_name) and attr == 'alt_text1':\n",
    "            return source.find(class_=class_name).span.contents[2].text.split()[0]\n",
    "        elif source.find(class_=class_name) and attr == 'alt_text2':\n",
    "            return source.find(class_=class_name).span.contents[0].text.split()[0]\n",
    "        elif source.find(class_=class_name) and attr == 'text':\n",
    "            return source.find(class_=class_name).text\n",
    "        else:\n",
    "            return np.NaN\n",
    "    except:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa9377a-392e-46d3-9c25-1892e963e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# launching the webdriver and the webpage to be scraped\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(5)\n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.flipkart.com\")\n",
    "\n",
    "search_box = driver.find_element(By.CLASS_NAME, \"Pke_EE\")\n",
    "search_box.click()\n",
    "search_box.send_keys(\"smartphone\")\n",
    "search_box.send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6170b86b-49dd-471d-9f5d-cd61ca2ccc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data scraped from the site will be stored in the below lists\n",
    "\n",
    "names,features,sp,mrp,discount,star,ratings,reviews = ([] for _ in range(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd33f892-e40b-4bc6-8d28-cdddda150723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional scraped that will be stored in the features list\n",
    "\n",
    "cols = ['Display Size', 'Resolution', 'Resolution Type', 'Display Type', 'Operating System', 'Processor Brand',\n",
    "        'Processor Type', 'Processor Core', 'Internal Storage', 'RAM', 'Primary Camera', 'Secondary Camera', 'Hybrid Sim Slot',\n",
    "        'Network Type', 'Micro USB Version', 'Bluetooth Version', 'Wi-Fi Version', 'NFC', 'Audio Jack', 'Battery Capacity',\n",
    "        'Width', 'Height', 'Depth', 'Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b3c587-9a17-4267-aca8-8e19c325dc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping data from multiple pages\n",
    "\n",
    "while True:\n",
    "    time.sleep(2)\n",
    "    srch_rslts = driver.current_url\n",
    "    soup = BeautifulSoup(driver.page_source)\n",
    "    phones_src = soup.find_all(class_=\"CGtC98\")\n",
    "\n",
    "    for src in phones_src:\n",
    "        \n",
    "        url = \"https://www.flipkart.com\" + src['href']\n",
    "        driver.get(url)\n",
    "        phone_soup = BeautifulSoup(driver.page_source)\n",
    "        phone_details = phone_soup.find(class_=\"DOjaWF gdgoEp col-8-12\")\n",
    "\n",
    "        try:\n",
    "            driver.find_element(By.XPATH,'//*[@class=\"VU-ZEz\"]').click()\n",
    "        except NoSuchElementException:\n",
    "            continue\n",
    "        \n",
    "        names.append(get_text(phone_details, \"VU-ZEz\", \"text\"))\n",
    "        sp.append(get_text(phone_details, \"Nx9bqj CxhGGd\", \"text\"))\n",
    "        mrp.append(get_text(phone_details, \"yRaY8j A6+E6v\", \"text\")) \n",
    "        discount.append(get_text(phone_details, \"UkUFwK WW8yVX\", \"text\"))  \n",
    "        star.append(get_text(phone_details, \"XQDdHH\", \"text\"))\n",
    "        ratings.append(get_text(phone_details, \"Wphh3N\", 'alt_text2'))\n",
    "        reviews.append(get_text(phone_details, \"Wphh3N\",  'alt_text1'))\n",
    "     \n",
    "        driver.find_element(By.XPATH, '//button[@class=\"QqFHMw _4FgsLt\"]').click()\n",
    "        param = [x.text for x in phone_details.find_all(class_=\"+fFi1w col col-3-12\")]\n",
    "        value = [x.text for x in phone_details.find_all(class_=\"HPETK2\")]\n",
    "        all_specs = dict(zip(param, value))\n",
    "        specs = {k:v for k,v in all_specs.items() if k in cols}\n",
    "        features.append(specs)\n",
    "\n",
    "    driver.get(srch_rslts)\n",
    "    \n",
    "    try:\n",
    "        driver.find_element(By.XPATH, '//*[text()=\"Next\"]').click()\n",
    "    except NoSuchElementException:\n",
    "        print(\"NoSuchElementException\")\n",
    "        \n",
    "    nxt_srch_rslts  = driver.current_url\n",
    "    if srch_rslts == nxt_srch_rslts:\n",
    "        print(\"No next page\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69010280-c88a-41ab-a4de-58b76fb243a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe of the scraped data\n",
    "\n",
    "data = {\"name\":names, \"sp\":sp, \"mrp\":mrp, \"discount\":discount, \"star\":star, \"ratings\":ratings, \"reviews\":reviews}\n",
    "\n",
    "df_data = pd.DataFrame(data)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aebd47-7533-4c44-8fe0-818a43943a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6128cf1d-26a5-450a-8ee5-0c0787c6593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe of the features from the features dictionary\n",
    "\n",
    "fts = pd.DataFrame(features)\n",
    "fts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a19f88-6c15-4f56-9c88-2214daf7929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff35a27-fba7-46e4-8168-785f6e6fe86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the main dataframe and the features dataframe \n",
    "\n",
    "df = df_data.join(fts, how='inner')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b798ddbc-b801-4692-9875-57bae0ceb946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting data for analysis\n",
    "\n",
    "df.to_excel(\"mobiles_data.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
